---
title: "Testing differences in categories"
author: "Tim Keighley"
teaching: 60
exercises: 30
questions:
- ""
objectives:
- "Choose the appropriate test for the data you have."
- ""
keypoints:
- "You can use _t_ tests and ANOVAs if you have a continuous response and categorical
  predictors."
source: "Rmd"
---

```{r setup, include=FALSE}
source("../bin/chunk-options.R")
```

```{r setup2, include=FALSE}
library(tidyverse)

path <- file.path("..", "data", "Pattani.xlsx")
pattani <- readxl::read_excel(path, sheet = "Data", skip = 1) %>%
  rename(blood_lead = `blood lead`, ln_blood_lead = `ln(blood lead)`) %>%
  mutate(gender = as_factor(gender), school = as_factor(school), water = as_factor(water))

cuckoo <- readr::read_csv(file.path("..", "data", "cuckoo.csv")) %>%
  mutate(Nest = as_factor(Nest))

theme_set(theme_bw())
```

## Numeric summaries of groups

In the previous lesson we looked at some visualisations of the data that suggested that there
might be differences between some of the groups, but we would like to test this.

To start, we might want to look at the different groups in numbers. We can use one of the
`tidyverse` packages, `dplyr`, to calculate these numbers.

```{r summarise, message=FALSE}
library(tidyverse)

pattani %>%
  summarise(mean = mean(blood_lead), sd = sd(blood_lead))
```

We don't get any results! Remember that the `blood_lead` variable had some missing values. By
default, the functions `mean` and `sd` will not give you a result if the input has missing
values. We can ask the functions to ignore them by using the argument `na.rm = TRUE`.

```{r summarise_narm}
pattani %>%
  summarise(mean = mean(blood_lead, na.rm = TRUE), sd = sd(blood_lead, na.rm = TRUE))
```

> ## Naming the arguments in `summarise`
>
> It isn't necessary to name the arguments in `summarise` but it makes the output neater.
{: .callout}

These give us the mean and standard deviation for the entire variable, but we want to split
that up by some other variables. For this we will use the `group_by` function.

```{r summarise_gender}
pattani %>%
  group_by(gender) %>%
  summarise(mean = mean(blood_lead, na.rm = TRUE), sd = sd(blood_lead, na.rm = TRUE))
```

Or by school:

```{r summarise_school}
pattani %>%
  group_by(school) %>%
  summarise(mean = mean(blood_lead, na.rm = TRUE), sd = sd(blood_lead, na.rm = TRUE))
```

You can also do both:

```{r summarise_gender_school}
pattani %>%
  group_by(gender, school) %>%
  summarise(mean = mean(blood_lead, na.rm = TRUE), sd = sd(blood_lead, na.rm = TRUE))
```

> ## Cuckoo egg lengths
>
> Find the mean and standard deviation for the cuckoo eggs by host nest type.
>
> > ## Solution
> >
> > ```{r cuckoo_summarise}
> > cuckoo %>%
> >   group_by(Nest) %>%
> >   summarise(mean = mean(Length), sd = sd(Length))
> > ```
> >
> > We don't have to use `na.rm = TRUE` because there aren't any missing values.
> {: .solution}
{: .challenge}

## Testing the difference between 2 groups

Going back to the difference by gender,

```{r summarise_gender2}
pattani %>%
  group_by(gender) %>%
  summarise(mean = mean(blood_lead, na.rm = TRUE), sd = sd(blood_lead, na.rm = TRUE))
```

We can see that the means of the boys are similar to the means of the girls, but we would like
to formally test if they are statistically different from each other. One way to do this is
with a **_t_ test**, using the R function `t.test`.

The question we are asking is **Is the mean blood lead level for the boys different to the mean
blood lead level for the girls?** <!-- Formally, we could say: $$H_0: \mu_{boys} = \mu_{girls} \\
H_1: \mu_{boys} \neq \mu_{girls}$$ -->

```{r, ttest}
t.test(blood_lead ~ gender, data = pattani)
```

Notice that the means shown for each group are the same as what we calculated earlier. The
**alternative hypothesis** is that the **difference in means is not equal to 0**, as we
mentioned. The **p-value** is
`r I(sprintf("%0.4f", t.test(blood_lead ~ gender, data = pattani)$p.value))`.
This indicates that the
the mean blood lead level for the boys and girls is not significantly different at the 0.05
level. The 95% confidence interval includes 0, which is another way to see that the means
are not different from each other.

## Analysis of Variance (ANOVA)

A **_t_ test** can only be used when you have 2 groups, like boys and girls, so we need to use
a different technique when you have more than 2 groups, like the 5 schools. This is the
**analysis of variance** or **ANOVA**. The main R function to perform this analysis is
`aov`. Be aware that there is also a function `anova` although this is used after you have
fit the model using `aov`.

One-way anova is a statistical technique that can be used to investigate the effect of a single
categorical predictor variable on a continuous response variable. The effect is measured by
looking at the values from different groups and comparing the averages. Of course, in any such
situation there will be variability. If the variability _within_ each group is noticeably less
than the variability _between_ the groups, then we decide that there are significant differences
between the groups.

One-way anova generalises the two-sample _t_ test. You can think of the two-sample _t_ test as
comparing the values from two groups. Alternatively, you can think of it as seeing whether the
grouping variable has an effect on the response variable (and so here we can look at grouping
variables with 3, 4 or more values).

You can still use ANOVAs for 2 groups:

```{r anova_gender}
gender_aov <- aov(blood_lead ~ gender, data = pattani)
gender_aov
```

This give us some information, but there are some other things that we might like to know,
like the p-value. Previously we used the `summary` function to get a summary of the data.
We can also use it to get a summary of an ANOVA object.

```{r anova_gender_summary}
summary(gender_aov)
```

Actually not that useful. But ANOVAs are a special type of linear model (which we will talk
about in more detail tomorrow) so we can directly call the `summary.lm` function which deals
with linear models.

```{r anovalm_gender_summary}
summary.lm(gender_aov)
```

Now we can see the p-value and several other pieces of information about the fitted model.
Looking at the line for the gender variable, you can see that the p-value is
`r I(sprintf("%0.4f", broom::glance(gender_aov)$p.value))`,
which is equivalent to the p-value from the _t_ test.
It is slightly different from the previous p-value because the standard
_t_ test makes slightly different assumptions from the ANOVA. We can get them to match by
using the `var.equal = TRUE` argument to `t.test`.

```{r, ttest2}
t.test(blood_lead ~ gender, data = pattani, var.equal = TRUE)
```

We should check if the model fit well. To do this we will need to get some of the parameters
from the fitted model. The `augment` function in the `broom` package helps with this.

```{r augment_aov}
gender_aov_augment <- broom::augment(gender_aov, pattani)
gender_aov_augment
```

One of the assumptions of the ANOVA model is that the residuals are Normally distributed.
Like before, we can use a QQ plot to check for normality.

```{r residual_qq}
ggplot(gender_aov_augment, aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```

The points deviate from the line, so the residuals are probably not normally distributed.
Something to consider, but we will move on with the model.

```{r resid_fits, eval=FALSE, include=FALSE}
ggplot(gender_aov_augment, aes(x = .fitted, y = .resid)) +
  geom_point()
```

### ANOVA with more than 2 groups

We have used ANOVA on a variable with 2 groups, which we could have done with a _t_ test, but
now we should use it on a variable with more than 2 groups.

```{r anova_school}
school_aov <- aov(blood_lead ~ school, data = pattani)
summary.lm(school_aov)
```

As a reminder, the names of the schools were `r I(paste(levels(pattani$school), sep = ", "))`.
Notice that the first school, `r I(levels(pattani$school)[1])`, does not appear in the
summary output. The other schools are being compared with this school. The p-values of all the
schools are less than 0.05, so they are all statistically different from the first school.
The overall p-value is also less than 0.05.

> ## Cuckoo egg lengths ANOVA
>
> Perform an ANOVA on the cuckoo data.
>
> > ## Solution
> >
> > ```{r cuckoo_anova}
> > cuckoo_aov <- aov(Length ~ Nest, data = cuckoo)
> > summary.lm(cuckoo_aov)
> > ```
> {: .solution}
{: .challenge}

Again, we should check the residuals to see if they are Normal.

```{r residual_school}
school_aov_augment <- broom::augment(school_aov, pattani)

ggplot(school_aov_augment, aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```

They seem closer to normality than the model with gender, but still a small amount of concern.

> ## Cuckoo ANOVA residuals
>
> Check the residuals for the cuckoo ANOVA.
>
> > ## Solution
> >
> > ```{r cuckoo_residuals}
> > cuckoo_aov_augment <- broom::augment(cuckoo_aov, cuckoo)
> >
> > ggplot(cuckoo_aov_augment, aes(sample = .resid)) +
> >   geom_qq() +
> >   geom_qq_line()
> > ```
> {: .solution}
{: .challenge}

### ANOVA with 2 variables

So far we have only looked at models with 1 variable. You can extend the ANOVA model to look
at multiple variables, for example both gender and school.

```{r anova_gensch}
both_aov <- aov(blood_lead ~ gender * school, data = pattani)
summary.lm(both_aov)
```

> ## A note on nesting models
> Another way of writing this model would be
> 
> ```{r, eval=FALSE}
> aov(blood_lead ~ gender + school + gender:school, data = pattani)
> ```
{: .callout}

The interaction term is not significant so we can run the model again without it.

```{r anova_gensch2}
both_aov2 <- aov(blood_lead ~ gender + school, data = pattani)
summary.lm(both_aov2)
```

We can compare these models with the `anova` function.

```{r compare_anova}
anova(school_aov, both_aov2, both_aov)
```

> ## Thanks
>
> Some of these notes are based on material in Moore, McCabe & Craig (2017), Peter
> Petocz's lecture notes for STAT270, and Drew Allen's _Intro to Statistics in R_ workshop.
{: .callout}

{% include links.md %}
