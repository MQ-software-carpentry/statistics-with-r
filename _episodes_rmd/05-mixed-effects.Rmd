---
title: "Mixed Effects & Bayesian Statistics"
author: "Dr Tania Prvan"
teaching: 60
exercises: 30
questions:
- ""
objectives:
- ""
keypoints:
- ""
source: "Rmd"
mathjax: true
---


```{r setup, include=FALSE}
source("../bin/chunk-options.R")

knitr::opts_chunk$set(echo = TRUE)
```

## PDF version + exercises

[PDF notes](../files/Day 3 Mixed Effects and Bayesian Statistics.pdf)

```{r load_libraries, message=FALSE}
library(tidyverse)
library(ggplot2)
library(lme4)
library(dplyr)
```


## 1 Mixed Effects Models

### 1.1 Simple Mixed Effects Models

**DEFN:** A unit of observation is an object about which information is collected. 

**EXAMPLES:** An individual. A family. A neighbourhood.

Units of observation may fall into groups or clusters.

**EXAMPLES:** Individuals could be nested in families. Individuals could be nested within schools. Individuals could be nested within neighbourhoods. Individuals could be nested within firms.

Longitudinal data also consist of clusters of observations made at different occasions for the same subject.

In clustered data it may be important to allow for correlations among the responses observed for units belonging to the same cluster.

**EXAMPLES:** Adult height of siblings (if have same parents) will be correlated because siblings are genetically related to each other and often have been raised within the same family.

We can model and estimate within cluster correlations using mixed effects models. The simplest model is where we don't have explanatory variables (predictors, independent variables).

Linear mixed effects models (sometimes called multilevel models depending on the context) have extra term(s) in addition to those found in the linear model (including multiple regression model) to allow for variation that is not explained by the independent variables of interest.

We will use the R package *lme4* to fit mixed effects models.

The following example is from Winter and Grawunder (2012). 

**EXAMPLE:** How is voice pitch is related to politeness? Subjects are asked to respond to hypothetical scenarios (independent variable, within subject) that are from either formal situations that require politeness or more informal situations and voice pitch is measured (dependent variable). Each subject is given a list of all the scenarios, so each subject gives multiple polite or informal responses. Gender is also recorded (independent variable, between-subject), since it is known to influence on voice pitch.

This could be modelled as

$$ \mbox{pitch} = \mbox{politeness} + \mbox{gender} + \epsilon $$

where we only have one error term which is our unexplained random variation.

Since each subject gave multiple responses (a repeated measures design) this model is inappropriate because the multiple responses made by one subject are not independent from each other. Also, every person has a slightly different pitch (frequency) which is a factor that affects all responses from the same subject so these responses will be correlated within the subject.

```{r read_politeness, message=FALSE}
mydata <- read_csv(file.path("..", "data", "politeness_data.csv"))

summary(mydata)
str(mydata)

table(mydata$subject)
table(mydata$subject, mydata$attitude)
```

We should look at the data using statistical graphics.

```{r polite_boxplots, warning=FALSE}
theme_set(theme_bw(base_size = 18))

qplot(attitude, frequency, facets = . ~ subject,
  colour = subject, geom = "boxplot", data = mydata)
```

Subjects F1, F2, F3 are female and M1, M2, M3 are male. You can see straight away that males have lower voices than females (as expected). But you can also see that, within the male and the female groups, there is lots of individual variation, with some people having relatively higher frequency values for their sex and others having relatively lower frequency values, regardless of the attitude. Within subjects we have correlation between frequency (pitch) and attitude (politeness).

```{r split_data, warning=FALSE}
polite   <- subset(mydata, attitude == "pol")
informal <- subset(mydata, attitude == "inf")

as_tibble(polite)
as_tibble(informal)

new <- data.frame(polite$frequency, informal$frequency)
names(new) <- c("Polite_Pitch", "Informal_Pitch")

ggplot(data = new, aes(x = Polite_Pitch, y = Informal_Pitch)) +
  geom_point() +
  geom_smooth(method = "lm")
```

**Modeling individual means with random intercepts**

These individual differences in our politeness example can be modelled by assuming different random intercepts for each subject. This is reasonable to do because our subjects can be thought of as a random sample from a (very large) population. Each participant is given a different intercept value (i.e., a different mean voice pitch). These intercepts can be estimated using the function $lmer$ in the package $lme$.

Our fixed effects model was
$$ \mbox{pitch} = \mbox{politeness} + \mbox{gender} + \epsilon $$
Our mixed effects model, using R syntax, is
$$ \mbox{pitch} = \mbox{politeness} + \mbox{gender} + \mbox{(1|subject)} + \epsilon $$
The term "(1|subject)" models the random intercept; that is, a different intercept is given for each subject and the 1 stands for intercept. The formula "(1|subject)" informs your model that it should expect multiple responses per subject, and these responses will depend on each subject’s baseline level. The non-independence arising from multiple responses by the same subject is now no longer a problem. We still have $\epsilon$ because even allowing for individual by-subject variation, there will still be “random” differences between different measurements made on the same subject.

Getting an idea of these different means:
```{r mean_freq}
pitch_bysubj <- with(mydata, aggregate(frequency ~ subject, FUN = "mean"))
pitch_bysubj
```
Now using the function *lmer* in the *lme4* package to fit the above mixed effects model:

```{r fit_polite_model}
fit1 <- lmer(frequency ~ (1 | subject), data = mydata)
# summary(fit1)
coef(fit1)$subject[1]
```
The estimates are very close to the actual mean frequencies (pitches).

It can be shown that the actual mean frequency (pitch) across subjects is the estimated Intercept, and the standard deviation across the subjects’ mean frequency (pitch) is the standard deviation (Std.Dev.) of the random effects.

```{r summary_stats}
mean(pitch_bysubj$frequency)
sd(pitch_bysubj$frequency)
```

Using the estimated intercepts for each subject

```{r model_coef}
mean(coef(fit1)$subject[1][, '(Intercept)'])
sd(coef(fit1)$subject[1][, '(Intercept)'])
```

This is also in the model output when using *summary*.

```{r model_summary}
summary(fit1)
```

**Including fixed effects**

We should also include the hypothesised scenario (polite vs informal) in our model. Recall that our original question was "How is voice pitch is related to politeness?". Since we know there is a gender difference this has to be controlled for in the model and since even within a subject there are differences this has to also be accomodated.

Our final model is

lmer(frequency ~ attitude+sex+(1|subject))
 
$$E(\mbox{pitch}_j)=\mbox{intercept}+\mbox{intercept}_j+\mbox{attitude}+\mbox{gender}$$
```{r mean_bycond}
mydata_bycond <- na.omit(mydata) %>%
  group_by(gender, attitude) %>%
  summarise(mean_pitch = mean(frequency))
  
ggplot(mydata_bycond, aes(x = attitude, y = mean_pitch, colour = gender, group = gender)) +
  geom_line(size = 2) +
  geom_point(size = 5, shape = 21, fill = "white")
```

Note we will use library *dplyr* which was loaded at the beginning.

We can also create contrasts. We will contrast code attitude and gender, so that we can see the effect of attitude at the “mean” between females and males, and the effect of gender at the mean between “informal” and “polite”.

```{r attitude_contrast}
mydata$attitude <- as_factor(mydata$attitude)

contrasts(mydata$attitude) <- cbind(inf_vs_pol = c(1, -1))
contrasts(mydata$attitude)
```

```{r gender_contrast}
mydata$gender <- as_factor(mydata$gender)

contrasts(mydata$gender) <- cbind(f_vs_m = c(1, -1))
contrasts(mydata$gender)
```

```{r fit_full_model}
fit2 <- lmer(frequency ~ attitude + gender + (1|subject), data = mydata)
summary(fit2)
```

Our mean frequency (pitch) is 192.883, pitch is lower higher for informal than polite scenarios, coefficient of attitudeinf_vs_pol=9.7105, t=3.203, and pitch (frequency) is higher for females than males, b=54.102, t=5.137. By a rough rule-of-thumb t is probably significant if it’s greater than 2. If time permits testing significance of parameter estimates will be discussed.

**More model information**

One useful measure to assess model fit is the AIC (An Information Criterion also known incorrectly as Akaike's Information Criterion according to an eminent Time Series researcher), which is $\mbox{deviance}+2∗(p+1)$, where $p$ is the number of parameters in the model (here, 1 is for the estimated residual variance, and $p$ is all the other parameters, e.g., our coefficents for fixed effects + our estimated variances, etc. for the random effects). Lower AICs are better, since higher deviances mean that the model is not fitting the data well. Since AIC increases as $p$ increases, AIC has a penalty term for more parameters.

$$\mbox{deviance}=−2∗\log \mbox{likelihood}$$

$$\mbox{AIC}=\mbox{deviance}+2\cdot(p+1)$$
```{r deviance}
logLikelihood <- logLik(fit2)
deviance = -2*logLikelihood[1];
deviance
```

**Extracting all the coefficients**

```{r pitch_bysubject_value}
mydata_bysubj = na.omit(mydata) %>%
  group_by(subject) %>%
  summarise(mean_pitch = mean(frequency))

ggplot(mydata_bysubj, aes(x=factor(subject), y=mean_pitch)) +
  geom_point(size=4, aes(colour = factor(subject)))
```

```{r model2_coef}
coef(fit2)
```

This model yields a separate intercept for each subject, in addition to a parameter estimate/slope for condition and gender that is constant across subjects. From here, we could try to estimate a given subject’s mean pitch based on these coefficients. To estimate subject F1’s mean ($\bar{x} =232.0357$) using their estimated intercept, and the effect of being a female:

```{r estimated_effect}
179.3003 + 0*(9.7) + 1*(54.10244)
```

```{r pitch_bysubject_values}
pitch_bysubj
```

It is very close.

**EXERCISE:**  Estimate M3's mean and compareit with the model fit.

**Random slopes**

In the models above the effect of politeness was the same for all subjects, hence one coefficient for politeness. However, the effect of politeness might be different for different subjects; that is, there might be a politeness*subject interaction. For example, it might be expected that some people are more polite in polite scenarios, others less. So, we need a random slope model, where subjects and items are not only allowed to have differing intercepts, but where they are also allowed to have different slopes for the effect of politeness (i.e., different effects of condition (attitude) on pitch (frequency)).

```r
lmer(pitch ~ condition + gender + (1 + condition | subject))
```

pitch for subject A = intercept + subject A's intercept shift + condition + subject A's condition slope shift + gender

Visualise the data by subject.

```{r pitch_bycond_plot}
mydata_bycond <- na.omit(mydata) %>%
  group_by(subject, attitude) %>%
  summarise(mean_pitch = mean(frequency))
  
ggplot(mydata_bycond, aes(x = attitude, y = mean_pitch, colour = subject, group = subject)) +
  geom_line(size = 2) +
  geom_point(size = 5, shape = 21, fill = "white")
```
The slopes don't look parallel.

Now fitting a model with random slopes.

```{r model_random_slopes}
fit3 <- lmer(frequency ~ attitude + gender + (1 + attitude | subject), REML = TRUE, data = mydata)
summary(fit3)
```
Let's check out the message. You do this by typing "?issingular" in R. Look at the information.

This model may not be suitable.

```{r coef_random_slopes}
coef(fit3)
```
Comparing the two models.

```{r compare_models}
anova(fit2, fit3, refit = FALSE)
```

Hardly any difference between the two deviances so you woud go for the simpler model. We already knew fit3 was problematic.
Formally, look at $\chi^2(2)=0.02$ which has p-value = 0.988, no point in having random slopes. Could have made the decision based on AIC values, you go for the model with the smaller AIC which is fit2. 

**Testing significance**

Debatable whether you should get p-values for models fitted using *lmer*, determining the degrees of freedom (df) is the sticking point. The *lmerTest* can be used to get approximation to dfs hence p-values.

**Model comparison**

A way to do this is likelihood ratio tests. Just like in multple linear regression you have a reduced model nested inside a full model. The test statistic is

$$D=-2 \cdot \log \frac{\mbox{likelihood for reduced model}}{\mbox{likelihood for full model}}$$
$$=-2\cdot \log (\mbox{likelihood for reduced model})+2 \cdot \log (\mbox{likelihood for full model})$$
$D$ has an approximate Chi-square distribution with $df(reduced)-df(full)$ degrees of freedom.

```{r models_with_gender}
fit4 <- lmer(frequency ~ gender + (1 | subject), REML = FALSE, data = mydata)
fit4b <- lmer(frequency ~ attitude + gender + (1 | subject), REML = FALSE, data = mydata)
anova(fit4, fit4b)
```

Gender needs to stay in the model (when you look at the output the full model has a highly significan p-value, p=0.003).

I won't be looking at REML versus ML.

**Item effects**

Still with the pitch example, different stimuli (here scenario) might cause a different value for "pitch" (frequency). If this true then, pitch for a given scenario  subject could be correlated across subjects, and even within a subject for the polite and informal attributes. This can be modelled this as a random effect.

```{r plot_scenario}
mydata$scenario <- factor(mydata$scenario)
ggplot(mydata, aes(x=scenario, y=frequency,  colour=scenario)) +
  geom_boxplot()
```

Scenario seems to influence pitch (frequency).

```{r model_with_scenario}
fit4 <- lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=mydata)
summary(fit4)
anova(fit2, fit4, refit=FALSE)
```
There appears to be a significant item (scenario) effect (p-value=0.0007796).

```{r coef_model_with_scenario}
coef(fit4)
ranef(fit4)
```

Similar to the random intercepts for subjects but we also have a mean level of pitch (frequency) for each scenario.

What happens when we vary the slope for each item?

```{r plot_by_scenario}
mydata_byscenario <- na.omit(mydata) %>%
  group_by(scenario, attitude) %>%
  summarise(mean_pitch = mean(frequency))
  
ggplot(mydata_byscenario, aes(x=attitude, y=mean_pitch, colour=scenario, group=scenario)) + geom_line() + geom_point(shape=21, fill="white")
```

```{r model_item_slopes}
fit4b<-lmer(frequency ~ attitude + gender + (1|subject) + (1 + attitude|scenario), data=mydata)
summary(fit4b)
anova(fit4, fit4b, refit=FALSE)
```
The p-value=0.8385 for the extra term in the full model is not significant, so having random slopes for scenario doesn't make much difference. That two scenarios are probably very similar in extracting similar differences between informal and polite situations.


Now we consider an example with regression.

```{r load_MASS, message=FALSE}
library(MASS)
```

The library MASS has the data set **oats**  which we can illustrate fitting a simple linear mixed effects model.

```{r show_oats}
as_tibble(oats)
str(oats)
```

The yield of oats from a split-plot field trial using three varieties and four levels of nitrogen  content. The experiment was laid out in 6 blocks of 3 main plots, each split into 4 sub-plots. The varieties were applied to the main plots and the nitrogen treatments to the sub-plots.

The original blocks come from an infinite number of possible blocks  so blocks should be a random effect. If you like, blocks are sampled from an infinite population.

```{r plot_oats}
p <- ggplot(data = oats, aes(N, Y)) + geom_point()
p + facet_grid(B ~ V)+theme_bw()
```
 
This is an example of a trellis graphic but when using ggplot you need to use facet_grid to get it. We have plotted Yield versus Nitrogen paneled by Block (rows) and Variety (columns). Always good, when possible, to obtain a visualisation of your data.
 
 More nitrogen higher the yield.


**Random effects**

If we can assume that a factor with $n$ levels comes from a probability distribution we have a random effect. So blocks are a random effect because they come from a factor with an infinite number of levels. The blocks can be put anywhere in the area under consideration.

**Mixed Effects Models**

Fixed **and** random effects 

**Classical Regression:** $Y=\alpha+\beta X +\varepsilon$

**Mixed Effects:** $Y=\alpha+\beta X + \gamma \cdot \zeta +\varepsilon$

We have the extra term $\gamma \cdot \zeta$ which is capturing the random effect.

If we just fitted a linear model to the data ignoring block.


```{r oats_linear_model}
model1 <- lm(Y ~ V * N, data = oats)

summary(model1)
```

Ignore p-values and just try to see what this model is fitting. Variety Golden Rain is the referrent category so the intercept is the Golden Rain yield for nitrogen equal zero so we have 80 bushels/hectare on average. Variety Marvellous would have on average 6.7 bushels/hectare yield more than Golden rain for no fertilser (nitrogen equals zero) whereas Variety Victory would have on average 8.5 bushels/hectare yield less than Golden rain for no fertiliser (nitrogen equals zero). Now nitrogen has been treated as a factor and its referrent category is no fertiliser (no nitrogen). Conditioning on all the other independent variables you see that as the nitrogen level increases so does the yield. If you now look at the interaction terms we can work out the expected (average) yield for each variety at each level of nitrogen.

**EXERCISE** Calculate the expected (average) yield for each variety of oats at each level of nitrogen. We already have done the calculation for no nitrogen.

The package `lme4` contains the function `lmer` which can be used to fit linear mixed effects models. Details can be found at <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> and <https://cran.r-project.org/web/packages/lme4/lme4.pdf>. The table of page 7 of the first reference gives an overview of the models that can be fitted using the `lme4` package.

Now fitting the mixed effects model for the oats data set.

```{r oats_mixed_model}
model2 <- lmer(Y ~ V*N + (1|B/V), data=oats)
summary(model2)
anova(model2)
```

Looking at Random effects: this gives the variance attributable at different levels of the design. We see that there was quite a bit of variation between blocks, between varieties and residuals variation between the  nitrogen concentrations. Now looking at the Fixed Effects and comparing to the model without random effects (model 1)we see that the estimated parameters are the same but the estimated standard deviations are different.

The take home message is that fitting a random effects model does not change the parameter estimates compared to fitting a model without random effects but that the standard deviations of the parameters are different.

```{r oats_coef}
coef(model1)
coef(model2)
```

The output looks quite different. For model2 every block and variety is given a different intercept (this came from the (1|B/V) which is setting up random intercepts for block (B) and variety (V) whereas for model1 the intercept is the same. Blocks were chosen from many potential blocks hence should be treated as a random effect and the three varieties have been chosen from many varieties hence a random effect. 

We know how to check model1 assumptions. We will now look at checking model2 assumptions.


**Diagnostics**

*Scatterplot of residuals*

```{r residual_scatter}
scatter.smooth(fitted(model2), resid(model2))
abline(h = 0, col = "tomato2")
```

*qq-plot of residuals*

```{r residual_qq_oats}
qqnorm(resid(model2))
qqline(resid(model2), col = "maroon4")
```

*Variance-checking plot:*

```{r check_variance}
scatter.smooth(fitted(model2), sqrt(abs(resid(model2))))
```

*qq-plot of standardized block random effects:*

```{r random_effects_qq}
qqnorm(ranef(model2)[[1]][, 1])
qqline(ranef(model2)[[1]][, 1], col = "steelblue4")
```

*qq-plot of standardized variety within block random effects:*

```{r random_effects_qq2}
qqnorm(ranef(model2)[[2]][, 1])
qqline(ranef(model2)[[2]][, 1], col = "violetred3")
```

*Check assumptions*

One slightly odd block when we first inspected the data.

```{r oats_model_plots}
plot(model2)
```
This looks like a random scatter about zero.

Now plot residuals.

```{r oats_random_effects_plot}
plot(ranef(model2))
```

The first plot is for the 18 combinations we get from the 6 blocks and 3 yields of wheat. 

The second plot is for the 6 blocks and one block obviously quite different from the rest.

**EXERCISE:** Work through this:
<https://bbolker.github.io/morelia_2018/notes/mixedlab.html>

**EXERCISE** Work through this <http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf> if you are getting lost or just want extra practice. It is an easier exercise.

**References**
Winter, B. (2013). Linear models and linear mixed effects models in R with linguistic applications. arXiv:1308.5499.

<https://web.stanford.edu/class/psych252/section/Mixed_models_tutorial.html#model-comparison>

<https://www.youtube.com/watch?v=VhMWPkTbXoY>

<https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/oats.html>

<https://www.statmethods.net/management/typeconversion.html>



<https://cran.r-project.org/web/packages/lme4/lme4.pdf>

<https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>

<https://www.r-bloggers.com/linear-mixed-models-in-r/>

<https://bbolker.github.io/morelia_2018/notes/mixedlab.html>

{% include links.md %}
