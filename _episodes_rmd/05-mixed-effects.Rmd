---
title: "Mixed Effects Models"
author: "Dr Tania Prvan"
teaching: 60
exercises: 30
questions:
- ""
objectives:
- ""
keypoints:
- ""
source: "Rmd"
mathjax: true
---

> ## Prerequisites
>
> * Experience with R, including importing, processing, and plotting of data.
> * Basic familiarity with multiple linear regression.
>
> R packages used: dplyr, ggplot2, lattice, lme4, lmerTest, readr
{: .prereq}


```{r setup, include=FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("05-")
knitr::opts_chunk$set(echo = TRUE)
```

> ## Discuss
>
> One assumption of multiple linear regression is that observations are independent of each other.
> What are examples where this assumption may be violated?
{: .challenge}

## Modelling clustered data

> ## Definition
>
> A unit of observation is an object about which information is collected independently of other units.
>
> Examples include an individual, a family, a neighbourhood.
{: .callout}

Units of observation may be *related* to each other, forming *groups* or *clusters*.

Individuals could be grouped in families, or schools. Families could be clustered by neighbourhood. Schools could be clustered by state.

Longitudinal data also consist of clusters of observations made at different occasions for the same subject.

Clustered data violate the assumption of independent observations. It is usually helpful, and often critical, to reflect the structure present in the data in the model. Careful modelling of these clusters will help you to separate variations in the response due to experimental conditions (or other effect of interest) from those that are due to the intrinsic structure of the data.

### Modelling the height of siblings

Let's look how this works with some real data. In this section we will analyse the height data collected by Francis Galton in 1885. It consists of the heights (measured in inches) of the adult children from 197 families. We start by importing the data.

```{r load_height_data}
library(readr)
height <- read_table2("../data/Galton.tab", col_types = cols(Family = col_character()))
height
```

As you can see there are 898 individual observations with information on family membership and gender. Before delving into the analysis we should take a closer look at the data.

```{r height_summary}
length(unique(height$Family))
table(height$Gender)
summary(height$Kids)
```

We would expect that height is influenced by gender. We can confirm this based on numerical and graphical summaries of the data. We'll use `dplyr` for processing the data and `ggplot2` for plotting.

```{r height_gender_summary, message=FALSE}
library(dplyr)
height %>% group_by(Gender) %>% summarise(mean=mean(Height)) %>% ungroup()
```

```{r, message=FALSE}
library(ggplot2)

ggplot(height, aes(x=Gender, y=Height, fill=Gender)) + geom_violin() + theme_bw()
```

Based on this, a reasonable first model might be to simply estimate the average height of males and females in the population. Using `lm` we can express this as

```{r height_lm}
fit_lm <- lm(Height ~ Gender, data=height)
```

We can look at some model diagnostics to confirm that this is an appropriate model.

```{r height_lm_qc}
qqnorm(rstandard(fit_lm))
qqline(rstandard(fit_lm), col=2)
```

> ## Exercise
>
> When fitting a linear regression model you should always inspect the residuals and their relationship with the fitted values. Usually a scatter plot is helpful for this purpose. Since this model only produces two different predictions (one for males and one for females), that isn't very helpful here.
>
> * What type of plot could you use to examine the residuals instead?
> * What would you expect that plot to look like?
> * Create and examine the plot.
>
> > ## Solution
> >
> > A boxplot or violin plot can help to summarise the distribution of residuals by group. Since the model simply estimates the mean heights of males and females a violin plot of the residuals should look very similar to the violin plot of heights above, but with the means of both groups aligned at 0.
> > ```{r}
> > ggplot(height, aes(x=Gender, y=resid(fit_lm), fill=Gender)) + geom_violin() + theme_bw()
> > ```
> {: .solution}
{: .challenge}

Now let's take a look at the model output:

```{r height_lm_summary}
summary(fit_lm)
```

According to this the average height of women is `r round(coef(fit_lm)[1], 2)` inches and
men are, on average, `r round(coef(fit_lm)[2], 2)` inches taller than women.

This all looks fairly reasonable but clearly there is a lot of variation in height not explained by gender. We would expect siblings to be somewhat similar in height as they share genetic factors through their parents and environmental factors through their shared upbringing.

We can model this structure of the data, children clustering in families, using linear mixed effects models. In addition to estimating population means (*fixed* effects) these models will also allow us to estimate how average family heights vary around these population means (*random* effects).

We will use the `lmer()` function from the `lme4` R package to fit mixed effects models.

```{r height_me}
library(lme4)

fit_me <- lmer(Height ~ Gender + (1|Family), data=height)
```

As you can see, `lmer()` uses a formula syntax similar to `lm()`. In addition to the already familiar fixed effect for gender this model includes an additional term, *(1\|Family)*. This specifies the random effect for family, indicating that the mean height of each family may differ from the population mean.

Now, let's take a closer look at the model.

```{r height_me_summary}
summary(fit_me)
```

In addition to the gender fixed effect that we have already seen in the simple linear regression model, this model also provides us with an estimate of the variance in average height between families (`r round(summary(fit_me)$varcor$Family,2)`) as well as the remaining (residual) variance within families (`r round(summary(fit_me)$sigma^2,2)`).

A dot plot, also known as a caterpillar plot, can help to visualise random effects. The `lme4` package, in conjunction with the `lattice` package, provides a convenient function to create these plots.

```{r height_dotplot}
library(lattice)

randoms <- ranef(fit_me)
dotplot(randoms)
```

This plot shows the deviation from the mean population height for each family, together with standard errors. Note how some families fall clearly below or above the population mean.

You can create QQ plots for random effects in a similar way, using the `qqmath()` function.

```{r height_qqplot}
qqmath(randoms)
```

#### Model comparison with `ranova()`

In this case it seems fairly clear that inclusion of the family random effect improves model fit. It is sometimes desirable to test whether inclusion of a specific random effect is justified, similar to how you would compare multiple regression models to test for the inclusion of (fixed) effects using likelihood ratio tests. Although `lme4` doesn't provide an easy way to do that, you can however, augment its abilities with the `lmerTest` package. To do so, you'll have to load the `lmerTest` package after `lme4` but prior to fitting the model.

```{r height_lmerTest, message=FALSE}
library(lme4)
library(lmerTest)

fit_me <- lmer(Height ~ Gender + (1|Family), data=height)
```

Then you can use the `ranova()` function to compare models with different random effects structure.

```{r height_ranova}
ranova(fit_me)
```

The comparison between the model with a random intercept for family (the mixed effects model) and the model without any random effects (the simple regression model) shows that the mixed effects model is clearly preferred.

The following example is from Winter and Grawunder (2012).

**EXAMPLE:** How is voice pitch related to politeness? Subjects are asked to respond to hypothetical scenarios (independent variable, within subject) that are from either formal situations that require politeness or more informal situations and voice pitch is measured (dependent variable). Each subject is given a list of all the scenarios, so each subject gives multiple polite or informal responses. Gender is also recorded (independent variable, between-subject), since it is known to influence on voice pitch.

This could be modelled as

$$ \mbox{pitch} = \mbox{politeness} + \mbox{gender} + \varepsilon $$

where we only have one error term which is our unexplained random variation.

Since each subject gave multiple responses (a repeated measures design) this model is inappropriate because the multiple responses made by one subject are not independent from each other. Also, every person has a slightly different pitch (frequency) which is a factor that affects all responses from the same subject so these responses will be correlated within the subject.

```{r read_politeness, message=FALSE}
mydata <- read_csv(file.path("..", "data", "politeness_data.csv"))

summary(mydata)
str(mydata)

table(mydata$subject)
table(mydata$subject, mydata$attitude)
```

We should look at the data using statistical graphics.

```{r polite_boxplots, warning=FALSE}
theme_set(theme_bw(base_size = 18))

qplot(attitude, frequency, facets = . ~ subject,
    colour = subject, geom = "boxplot", data = mydata)
```

Subjects F1, F2, F3 are female and M1, M2, M3 are male. You can see straight away that males have lower voices than females (as expected). But you can also see that, within the male and the female groups, there is lots of individual variation, with some people having relatively higher frequency values for their sex and others having relatively lower frequency values, regardless of the attitude. Within subjects we have correlation between frequency (pitch) and attitude (politeness).

```{r split_data, warning=FALSE}
polite   <- subset(mydata, attitude == "pol")
informal <- subset(mydata, attitude == "inf")

as_tibble(polite)
as_tibble(informal)

new <- data.frame(polite$frequency, informal$frequency)
names(new) <- c("Polite_Pitch", "Informal_Pitch")

ggplot(data = new, aes(x = Polite_Pitch, y = Informal_Pitch)) +
    geom_point() +
    geom_smooth(method = "lm")
```

#### Modeling individual means with random intercepts

These individual differences in our politeness example can be modelled by assuming different random intercepts for each subject. This is reasonable to do because our subjects can be thought of as a random sample from a (very large) population. Each participant is given a different intercept value (i.e., a different mean voice pitch). These intercepts can be estimated using the function `lmer` in the package `lme`.

Our fixed effects model was

$$ \mbox{pitch} = \mbox{politeness} + \mbox{gender} + \varepsilon $$

Our mixed effects model, using R syntax, is

$$ \mbox{pitch} = \mbox{politeness} + \mbox{gender} + \mbox{(1|subject)} + \varepsilon $$

The term `(1|subject)` models the random intercept; that is, a different intercept is given for each subject and the 1 stands for intercept. The formula `(1|subject)` informs your model that it should expect multiple responses per subject, and these responses will depend on each subject’s baseline level. The non-independence arising from multiple responses by the same subject is now no longer a problem. We still have $\varepsilon$ because even allowing for individual by-subject variation, there will still be “random” differences between different measurements made on the same subject.

Getting an idea of these different means:

```{r mean_freq}
pitch_bysubj <- with(mydata, aggregate(frequency ~ subject, FUN = "mean"))
pitch_bysubj
```

Now using the function `lmer` in the `lme4` package to fit the above mixed effects model:

```{r fit_polite_model}
fit1 <- lmer(frequency ~ (1 | subject), data = mydata)
# summary(fit1)
coef(fit1)$subject[1]
```

The estimates are very close to the actual mean frequencies (pitches).

It can be shown that the actual mean frequency (pitch) across subjects is the estimated Intercept, and the standard deviation across the subjects’ mean frequency (pitch) is the standard deviation (Std.Dev.) of the random effects.

```{r summary_stats}
mean(pitch_bysubj$frequency)
sd(pitch_bysubj$frequency)
```

Using the estimated intercepts for each subject

```{r model_coef}
mean(coef(fit1)$subject[1][, '(Intercept)'])
sd(coef(fit1)$subject[1][, '(Intercept)'])
```

This is also in the model output when using `summary`.

```{r model_summary}
summary(fit1)
```

#### Including fixed effects

We should also include the hypothesised scenario (polite vs informal) in our model. Recall that our original question was "How is voice pitch is related to politeness?". Since we know there is a gender difference this has to be controlled for in the model and since even within a subject there are differences this has to also be accomodated.

Our final model is

```r
lmer(frequency ~ attitude+sex+(1|subject))
```

$$E(\mbox{pitch}_j)=\mbox{intercept}+\mbox{intercept}_j+\mbox{attitude}+\mbox{gender}$$

```{r mean_bycond}
mydata_bycond <- na.omit(mydata) %>%
    group_by(gender, attitude) %>%
    summarise(mean_pitch = mean(frequency))

ggplot(mydata_bycond, aes(x = attitude, y = mean_pitch, colour = gender, group = gender)) +
    geom_line(size = 2) +
    geom_point(size = 5, shape = 21, fill = "white")
```

Note we will use library `dplyr` which was loaded at the beginning.

We can also create contrasts. We will contrast code attitude and gender, so that we can see the effect of attitude at the “mean” between females and males, and the effect of gender at the mean between “informal” and “polite”.

```{r attitude_contrast}
mydata$attitude <- as_factor(mydata$attitude)

contrasts(mydata$attitude) <- cbind(inf_vs_pol = c(1, -1))
contrasts(mydata$attitude)
```

```{r gender_contrast}
mydata$gender <- as_factor(mydata$gender)

contrasts(mydata$gender) <- cbind(f_vs_m = c(1, -1))
contrasts(mydata$gender)
```

```{r fit_full_model}
fit2 <- lmer(frequency ~ attitude + gender + (1|subject), data = mydata)
summary(fit2)
```

Our mean frequency (pitch) is 192.883, pitch is lower higher for informal than polite scenarios, coefficient of attitudeinf_vs_pol=9.7105, t=3.203, and pitch (frequency) is higher for females than males, b=54.102, t=5.137. By a rough rule-of-thumb _t_ is probably significant if it’s greater than 2. If time permits, testing significance of parameter estimates will be discussed.

#### More model information

One useful measure to assess model fit is the AIC (An Information Criterion also known incorrectly as Akaike's Information Criterion according to an eminent Time Series researcher), which is $\mbox{deviance}+2∗(p+1)$, where $p$ is the number of parameters in the model (here, 1 is for the estimated residual variance, and $p$ is all the other parameters, e.g., our coefficents for fixed effects + our estimated variances, etc. for the random effects). Lower AICs are better, since higher deviances mean that the model is not fitting the data well. Since AIC increases as $p$ increases, AIC has a penalty term for more parameters.

$$\mbox{deviance}=−2∗\log \mbox{likelihood}$$

$$\mbox{AIC}=\mbox{deviance}+2\cdot(p+1)$$

```{r deviance}
logLikelihood <- logLik(fit2)
deviance <- -2 * logLikelihood[1]
deviance
```

#### Extracting all the coefficients

```{r pitch_bysubject_value}
mydata_bysubj <- na.omit(mydata) %>%
    group_by(subject) %>%
    summarise(mean_pitch = mean(frequency))

ggplot(mydata_bysubj, aes(x = factor(subject), y = mean_pitch)) +
    geom_point(size = 4, aes(colour = factor(subject)))
```

```{r model2_coef}
coef(fit2)
```

This model yields a separate intercept for each subject, in addition to a parameter estimate/slope for condition and gender that is constant across subjects. From here, we could try to estimate a given subject’s mean pitch based on these coefficients. To estimate subject F1’s mean ($\bar{x} =232.0357$) using their estimated intercept, and the effect of being a female:

```{r estimated_effect}
179.3003 + 0 * (9.7) + 1 * (54.10244)
```

```{r pitch_bysubject_values}
pitch_bysubj
```

It is very close.

**EXERCISE:**  Estimate M3's mean and compare it with the model fit.

#### Random slopes

In the models above the effect of politeness was the same for all subjects, hence one coefficient for politeness. However, the effect of politeness might be different for different subjects; that is, there might be a politeness*subject interaction. For example, it might be expected that some people are more polite in polite scenarios, others less. So, we need a random slope model, where subjects and items are not only allowed to have differing intercepts, but where they are also allowed to have different slopes for the effect of politeness (i.e., different effects of condition (attitude) on pitch (frequency)).

```r
lmer(pitch ~ attitude + gender + (1 + attitude | subject))
```

pitch for subject A = intercept + subject A's intercept shift + condition + subject A's condition slope shift + gender

##### Visualise the data by subject

```{r pitch_bycond_plot}
mydata_bycond <- na.omit(mydata) %>%
    group_by(subject, attitude) %>%
    summarise(mean_pitch = mean(frequency))

ggplot(mydata_bycond, aes(x = attitude, y = mean_pitch, colour = subject, group = subject)) +
    geom_line(size = 2) +
    geom_point(size = 5, shape = 21, fill = "white")
```

The slopes don't look parallel.

Now fitting a model with random slopes.

```{r model_random_slopes}
fit3 <- lmer(frequency ~ attitude + gender + (1 + attitude | subject),
    REML = TRUE, data = mydata)
summary(fit3)
```

Let's check out the message. You do this by typing `?isSingular` in R. Look at the information.

This model may not be suitable.

```{r coef_random_slopes}
coef(fit3)
```

Comparing the two models.

```{r compare_models}
anova(fit2, fit3, refit = FALSE)
```

Hardly any difference between the two deviances so you woud go for the simpler model. We already knew `fit3` was problematic.
Formally, look at $\chi^2(2)=0.02$ which has p-value = 0.988, no point in having random slopes. Could have made the decision based on AIC values, you go for the model with the smaller AIC which is `fit2`.

#### Testing significance

Debatable whether you should get p-values for models fitted using `lmer`, determining the degrees of freedom (df) is the sticking point. The `lmerTest` can be used to get approximation to dfs hence p-values.

#### Model comparison

A way to do this is likelihood ratio tests. Just like in multiple linear regression you have a reduced model nested inside a full model. The test statistic is

$$D=-2 \cdot \log \frac{\mbox{likelihood for reduced model}}{\mbox{likelihood for full model}}$$

$$=-2\cdot \log (\mbox{likelihood for reduced model})+2 \cdot \log (\mbox{likelihood for full model})$$

$D$ has an approximate Chi-square distribution with $df(reduced)-df(full)$ degrees of freedom.

```{r models_with_gender}
fit4 <- lmer(frequency ~ gender + (1 | subject), REML = FALSE, data = mydata)
fit4b <- lmer(frequency ~ attitude + gender + (1 | subject), REML = FALSE, data = mydata)

anova(fit4, fit4b)
```

Attitude needs to stay in the model (when you look at the output the full model has a highly significan p-value, p=0.003).

I won't be looking at REML versus ML.

#### Item effects

Still with the pitch example, different stimuli (here scenario) might cause a different value for "pitch" (frequency). If this true then, pitch for a given scenario subject could be correlated across subjects, and even within a subject for the polite and informal attributes. This can be modelled this as a random effect.

```{r plot_scenario, warning=FALSE}
mydata$scenario <- factor(mydata$scenario)

ggplot(mydata, aes(x = scenario, y = frequency, colour = scenario)) +
    geom_boxplot()
```

Scenario seems to influence pitch (frequency).

```{r model_with_scenario}
fit4 <- lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data = mydata)

summary(fit4)
anova(fit2, fit4, refit = FALSE)
```

There appears to be a significant item (scenario) effect (p-value=0.0007796).

```{r coef_model_with_scenario}
coef(fit4)
ranef(fit4)
```

Similar to the random intercepts for subjects but we also have a mean level of pitch (frequency) for each scenario.

What happens when we vary the slope for each item?

```{r plot_by_scenario}
mydata_byscenario <- na.omit(mydata) %>%
    group_by(scenario, attitude) %>%
    summarise(mean_pitch = mean(frequency))

ggplot(mydata_byscenario, aes(x = attitude, y = mean_pitch, colour = scenario, group = scenario)) +
    geom_line() +
    geom_point(shape = 21, fill = "white")
```

```{r model_item_slopes}
fit4b <- lmer(frequency ~ attitude + gender + (1|subject) + (1 + attitude|scenario),
    data = mydata)

summary(fit4b)
anova(fit4, fit4b, refit = FALSE)
```

The p-value=0.8385 for the extra term in the full model is not significant, so having random slopes for scenario doesn't make much difference. That two scenarios are probably very similar in extracting similar differences between informal and polite situations.

Now we consider an example with regression.

```{r load_MASS, message=FALSE}
library(MASS)
```

The library MASS has the data set `oats` which we can illustrate fitting a simple linear mixed effects model.

```{r show_oats}
as_tibble(oats)
str(oats)
```

The yield of oats from a split-plot field trial using three varieties and four levels of nitrogen content. The experiment was laid out in 6 blocks of 3 main plots, each split into 4 sub-plots. The varieties were applied to the main plots and the nitrogen treatments to the sub-plots.

The original blocks come from an infinite number of possible blocks so blocks should be a random effect. If you like, blocks are sampled from an infinite population.

```{r plot_oats}
ggplot(data = oats, aes(N, Y)) +
    geom_point() +
    facet_grid(B ~ V)
```

This is an example of a trellis graphic but when using `ggplot` you need to use `facet_grid` to get it. We have plotted Yield versus Nitrogen paneled by Block (rows) and Variety (columns). Always good, when possible, to obtain a visualisation of your data.

More nitrogen higher the yield.

#### Random effects

If we can assume that a factor with $n$ levels comes from a probability distribution we have a random effect. So blocks are a random effect because they come from a factor with an infinite number of levels. The blocks can be put anywhere in the area under consideration.

#### Mixed Effects Models

Fixed **and** random effects

**Classical Regression:** $Y=\alpha+\beta X +\varepsilon$

**Mixed Effects:** $Y=\alpha+\beta X + \gamma \cdot \zeta +\varepsilon$

We have the extra term $\gamma \cdot \zeta$ which is capturing the random effect.

If we just fitted a linear model to the data ignoring block.

```{r oats_linear_model}
model1 <- lm(Y ~ V * N, data = oats)

summary(model1)
```

Ignore p-values and just try to see what this model is fitting. Variety Golden Rain is the referrent category so the intercept is the Golden Rain yield for nitrogen equal zero so we have 80 bushels/hectare on average. Variety Marvellous would have on average 6.7 bushels/hectare yield more than Golden rain for no fertilser (nitrogen equals zero) whereas Variety Victory would have on average 8.5 bushels/hectare yield less than Golden rain for no fertiliser (nitrogen equals zero). Now nitrogen has been treated as a factor and its referrent category is no fertiliser (no nitrogen). Conditioning on all the other independent variables you see that as the nitrogen level increases so does the yield. If you now look at the interaction terms we can work out the expected (average) yield for each variety at each level of nitrogen.

**EXERCISE** Calculate the expected (average) yield for each variety of oats at each level of nitrogen. We already have done the calculation for no nitrogen.

The package `lme4` contains the function `lmer` which can be used to fit linear mixed effects models. Details can be found at <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> and <https://cran.r-project.org/web/packages/lme4/lme4.pdf>. The table of page 7 of the first reference gives an overview of the models that can be fitted using the `lme4` package.

Now fitting the mixed effects model for the oats data set.

```{r oats_mixed_model}
model2 <- lmer(Y ~ V*N + (1|B/V), data = oats)

summary(model2)
anova(model2)
```

Looking at Random effects: this gives the variance attributable at different levels of the design. We see that there was quite a bit of variation between blocks, between varieties and residuals variation between the  nitrogen concentrations. Now looking at the Fixed Effects and comparing to the model without random effects (model 1) we see that the estimated parameters are the same but the estimated standard deviations are different.

The take home message is that fitting a random effects model does not change the parameter estimates compared to fitting a model without random effects but that the standard deviations of the parameters are different.

```{r oats_coef}
coef(model1)
coef(model2)
```

The output looks quite different. For `model2` every block and variety is given a different intercept (this came from the `(1|B/V)` which is setting up random intercepts for block (`B`) and variety (`V`) whereas for `model1` the intercept is the same). Blocks were chosen from many potential blocks hence should be treated as a random effect and the three varieties have been chosen from many varieties hence a random effect.

We know how to check `model1` assumptions. We will now look at checking `model2` assumptions.

#### Diagnostics

*Scatterplot of residuals*

```{r residual_scatter}
scatter.smooth(fitted(model2), resid(model2))
abline(h = 0, col = "tomato2")
```

*qq-plot of residuals*

```{r residual_qq_oats}
qqnorm(resid(model2))
qqline(resid(model2), col = "maroon4")
```

*Variance-checking plot:*

```{r check_variance}
scatter.smooth(fitted(model2), sqrt(abs(resid(model2))))
```

*qq-plot of standardized block random effects:*

```{r random_effects_qq}
qqnorm(ranef(model2)[[1]][, 1])
qqline(ranef(model2)[[1]][, 1], col = "steelblue4")
```

*qq-plot of standardized variety within block random effects:*

```{r random_effects_qq2}
qqnorm(ranef(model2)[[2]][, 1])
qqline(ranef(model2)[[2]][, 1], col = "violetred3")
```

#### Check assumptions

One slightly odd block when we first inspected the data.

```{r oats_model_plots}
plot(model2)
```

This looks like a random scatter about zero.

Now plot residuals.

```{r oats_random_effects_plot}
plot(ranef(model2))
```

The first plot is for the 18 combinations we get from the 6 blocks and 3 yields of wheat.

The second plot is for the 6 blocks and one block obviously quite different from the rest.

**EXERCISE:** Work through this:
<https://bbolker.github.io/morelia_2018/notes/mixedlab.html>

**EXERCISE** Work through this <http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf> if you are getting lost or just want extra practice. It is an easier exercise.

## References

Winter, B. (2013). Linear models and linear mixed effects models in R with linguistic applications. arXiv:1308.5499.

<https://web.stanford.edu/class/psych252/section/Mixed_models_tutorial.html#model-comparison>

<https://www.youtube.com/watch?v=VhMWPkTbXoY>

<https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/oats.html>

<https://www.statmethods.net/management/typeconversion.html>

<https://cran.r-project.org/web/packages/lme4/lme4.pdf>

<https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>

<https://www.r-bloggers.com/linear-mixed-models-in-r/>

<https://bbolker.github.io/morelia_2018/notes/mixedlab.html>

{% include links.md %}
